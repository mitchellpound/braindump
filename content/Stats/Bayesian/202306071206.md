---
title: Posterior prediction vs.  parametric bootstrap
draft: false
---
# Posterior prediction vs.  parametric bootstrap
The [[202306062133|Posterior Predictive Distribution]] and the [[202306071155|Parametric Bootstrap]] are both very similar in how you do them. Both use repeated sampling based on the observed data to make a distribution. 

The main difference is the parametric bootstrap uses a point estimate (probably the [[202306071208|MLE]]) in the distribution to pull realizations from. So you are sampling from $f(Y|\hat\theta)$, and using the same $\hat\theta$ value every time.

On the other hand, [[202306062202|Bayesian prediction algorithm]] samples a $\theta$ value from the posterior to use to get the realizations $f(Y|\theta)$. So you are using different $\theta$'s each time for each new sample of $Y$ you simulate. This takes into account the uncertainty of the $\theta$ parameter - instead it uses the prior updated through Bayes Rule.

---
### References
[[@lancaster2004]] - Chapter 2