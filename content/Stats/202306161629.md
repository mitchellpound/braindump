---
title: Markov chain matrix
draft: false
---
# Markov chain matrix
[[202306161624|Markov chain]] can be compactly/ efficiently described using matrices + vectors. 

For a vector or probabilities (can be a prior distribution) of the possible states $\vec s_t$:

$$\vec s_{t+1} = A\vec s_t$$

$A$ is the transition matrix where $a_{ij} = P(S_{t+1} = q_i|S_t = q_j)$

Note that the columns of the transition matrix must add up to 1. The probabilities of all the possible states given a current state must add up to 1 by probability axioms. 

---
### References
- [[@lancaster2004]]
- [[@sucar2020]]
